trainer:
  gpus: -1
  distributed_backend: "dp"
  accumulate_grad_batches: 1
  profiler: False
  max_epochs: 2000

scheduler:
  type: MultiStepLR
  args: 
    milestones: [100, 400, 900] #[6, 8, 18]
    gamma: 0.1

optimizer:
  type: Adam
  args:
    lr: 0.0002

environment:
  server:
    port: 41451
  position:
    start:
      x:   0.0
      y:   0.0
      z: -10.0
    end:
      x: 100.0
      y:   0.0
      z: -10.0
  quaternion:
    start:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
    end:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
  reward:
    goal: 1000
    collision: -100
    factor: 0.001
  sensor:
    signal_strength_factor: 0.01
  agent:
    velocity_factor: 2
    

dataset:
  loader:
    batch_size: 16
    num_workers: 4
    #shuffle: True
    #sampler: None   

model:
  actor:
    in_channels: 9
    action_dim: 3
    init_w: 3e-3
  critic:
    in_channels: 9
    action_dim: 3
    init_w: 3e-3
  tau: 0.001
  replay_buffer_size: 160
  in_channels: 3
  actions: 6
  max_epsilon: 0.9
  min_epsilon: 0.1
  stop_decay: 10000
  sync_rate: 30
  gamma: 0.99
  sample_size: 80
  thresh_dist: 10
  max_episode: 80

