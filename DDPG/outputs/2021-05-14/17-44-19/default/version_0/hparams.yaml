trainer:
  gpus: -1
  distributed_backend: dp
  accumulate_grad_batches: 1
  profiler: false
  max_epochs: 2000
scheduler:
  type: MultiStepLR
  args:
    milestones:
    - 100
    - 400
    - 900
    gamma: 0.1
optimizer:
  type: SGD
  args:
    lr: 0.0002
    momentum: 0.2
environment:
  server:
    port: 41451
  position:
    start:
      x: 0.0
      'y': 0.0
      z: -10.0
    end:
      x: 100.0
      'y': 0.0
      z: -10.0
  quaternion:
    start:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
    end:
      w_val: 1.0
      x_val: 0.0
      y_val: 0.0
      z_val: 0.0
  reward:
    goal: 1000.0
    collision: -100.0
    factor: 0.001
  agent:
    velocity_factor: 2
dataset:
  loader:
    batch_size: 16
    num_workers: 4
model:
  actor:
    in_channels: 9
    action_dim: 3
    init_w: 0.003
  critic:
    in_channels: 9
    action_dim: 3
    init_w: 0.003
  tau: 0.001
  replay_buffer_size: 160
  in_channels: 3
  actions: 6
  max_epsilon: 0.9
  min_epsilon: 0.1
  stop_decay: 10000
  sync_rate: 30
  gamma: 0.99
  sample_size: 80
  thresh_dist: 10
  max_episode: 80
